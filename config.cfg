## only one of the two URL values should be used, REMOTE_BASE_URL will have preference over LOCAL_BASE_URL
# in case of port conflit, please modify the port
# keep the LOCAL_MODEL_URI empty if your model server is running on a different machine
# For local server this is harcoded, please do not change for LOCAL 
REMOTE_BASE_URL=""
REMOTE_API_KEY=""
LOCAL_BASE_URL="http://localhost:8000/v1"
LOCAL_API_KEY="NONE" 

# model configuration
MODEL_FILE="ZySec-7B.Q8_0.gguf"
# Allowed Values for MODEL_FILE
## MISTRAL FINE TUNED Check the page before changing
#ZySec-7B.Q2_K.gguf
#ZySec-7B.Q4_K_M.gguf
#ZySec-7B.Q8_0.gguf


## llama server configuration
BATCH_SIZE=4
GPU_LAYERS=50 # no of layers to be put on GPU. 
CONTEXT_LENGTH=8196 # based on the model 
ENABLE_MODEL_SERVER_LOG="no" # choosing yes will enable model logs and create a server.log file in the main direcotry, enable yes if server is failing and need to debug
